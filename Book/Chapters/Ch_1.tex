\chapter{Introductory Theory}
    \section{Project's Background}
        Our work cannot be understood if we don't take into account our tutor's research group's current line of research. That is no other than \textbf{network resilience} and how we can improve it. Their approach is broadly based on modeling a network infrastructure as a multilayered construct where the upper layers get closer and closer to reality as we continue climbing them down. We can see how this approach is quite similar to that of conceptual network stacks such as the ones running today's Internet.\\

        The above line of work has produced some high-quality papers worth of theory. We mustn't forget that we are engineers nonetheless, which means we ought to look for a real-world application for our solutions. In an effort to somehow experimentally measure the effectiveness of the defense strategies proposed by the group's research we have been tasked with the development of a testing \textit{framework}. Said \textit{framework} needs to somehow \textit{emulate} an arbitrary network topology on which we can operate in such a way that we can mimic real world attacks. By applying the researched mitigation strategies on said scenario we plan on being able to settle which do best based on the current threat and network topology.\\

        \subsection{Simulation vs Emulation}
            These two terms are often used interchangeably when referring to tools whose mission is providing the user with a scenario resembling the real world in some sort of way. Even though both terms share the same purpose the way in which the accomplish it is radically different.\\

            \textbf{Simulation} leverages the theory capable of modeling real world phenomena. The clearest example may be physics. Physics let us model the world that surrounds us through math. That is why we can leverage the pertaining equations to compute the outcome of any scenario we can describe. Thus, Simulation \textbf{computes} an outcome based on the initial parameters and the model we have built for describing the system under study. This implies that simulation is limited by how good our models are. If an equation doesn't take an aspect into account that means it won't affect the simulation's outcome which in turn can result in inaccurate results. Techniques used for simulating systems include discrete event and agent based simulations such as those used by the well known \texttt{Any Logic}.\\

            \textbf{Emulation}, on the other hand, tries to recreate the system under study to then perform experiments on it. If we manage to craft a detailed enough model, we could even get a glimpse of unexpected behaviors we hadn't taken into account. This is why emulation is often the preferred approach. Nonetheless, it is harder to recreate a system than it is to describe its expected behavior. In our project we have nonetheless decided to go with emulation so that we reaped the most useful information from our experiments.\\

    % TODO: Add images from: https://www.docker.com/resources/what-container
    \section{Outlining the Implementation}
        Given our objective we need to come up with a way of emulating a whole network. Now, the initial impulse we had was to leverage the current virtualization capabilities offered by tools such as \texttt{VirtualBox} or \texttt{VMWare}. We were also aware of other existing solutions such as the \textbf{container} technology offered by \texttt{docker} for instance. What's more, we also knew of the existence of orchestration tools such as \texttt{kubernetes} which were aimed at employing several containers in a cooperative and organized manner. Given we need to build a network, no matter what technology we end up using, one may believe \texttt{kubernetes} to be quite a handy addition to our tool belt. We'll walk through what each of the above offer and how they accomplish their goals in an effort to decide which of them to employ as the cornerstone for our work.

        \subsection{Virtual Machines (VMs)}
            In today's world, technology firms tend to lock their products up and make them incompatible with other industry solutions in an effort to bite the biggest possible chunk out of the possible user base for their assets. This has left many end users having to cope with running several operating systems (OSs) on a single machine so that we had access to particular programs such as the \texttt{COMNET III} GSM Network Simulator for example.\\

            Odds are that in order to have several operating systems coexisting we have turned to the power offered by Virtual Machines. Put simply, VMs \textit{emulate} a whole \texttt{guest} operating system within a \texttt{host} OS. In order to do so, virtualization solutions like the ones we mentioned before leverage the capabilities of a "middleman" known as the \texttt{hypervisor}. This \texttt{hypervisor} may be implemented in hardware or software and it provides an interface letting \texttt{guest} operating systems share the available computing resources with the \texttt{host} OS.\\

            Even though we find the above topic extremely interesting we are not concerned with aspects such as the amount of CPU time or memory that would be devoted to our VM. We, on the contrary, are mostly concerned with what happens with the network infrastructure. After all, our aim is creating a virtualized network and so we need to know how the virtual network attached to the created VMs is set up. We know that the VMs actually have Internet connectivity through the \texttt{host} OS so there must be some sort of "infrastructure" supporting said connections. Nonetheless and before we consider VMs as a feasible solution we need to think about how the'll scale.\\

            The network topologies we have been charged with virtualizing are not small. Our largest working topology consists of $45$ nodes, of which $36$ would need to be implemented as a VM instance. Given how resource intensive VMs are when compared to other solutions like containers these numbers are too large to be handled in terms of virtual machines. If we just consider the amount of memory we would need to devote for them on our $8\ GB\bigr\rvert_{RAM}$ machine we would be looking at roughly $234\ MB\bigr\rvert_{RAM}$ for each of them and even then we would have no memory for the \texttt{host} OS at all. On top of that, the image for \texttt{Ubuntu 20.04} weighs $958,4\ MB$. It would be cumbersome to get it below that threshold as we would need to strip the \textit{vanilla} version of any features we don't need and we would then have to re-package the result. Even then, we would be looking at around $72\ GB$ of used \texttt{HDD} space if we were to allocate $2\ GB$ of \texttt{HDD} space to each and every VM we were to bring up.\\

            Even though the above requirements could be eventually met it's easy to see how this approach wouldn't scale much further than it already has if running it on consumer grade platforms. We can then conclude how the fact that VMs are just "whole" operating systems makes them too cumbersome to handle and too "big" to be instantiated all the times we need them. On top of that and even though we didn't dig that deep into the underlying network infrastructure, it seems to be "darker" and less documented than that offered by others like \texttt{docker}. Then, although VMs are a perfect fit for many scenarios that is not our case. Knowing what set us back we'll now analyze the \texttt{container} technology to find out how it's a perfect way to get started for us.

        \subsection{Containers}
            Before beginning to discuss whether containers are suitable for our purpose we should begin by describing what a \texttt{container} really is as it can be a confusing actor in the virtualization realm.\\

            According to \href{docker.com}{https://www.docker.com/resources/what-container}, \textit{a container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another}. Now, this definition is a perfect representative of the main kind of problems we'll have to face when trying to bend containers to our will throughout the development. Containers are born to try and increase the portability of applications. In todays Internet-centric society where we all want uninterrupted services it's critical to be able to change an applications environment at a moment's notice due to outrages, ending support cycles for software, security breaches... That's why the container technology has developed with such an enormous speed. It provides the infrastructure for a reliable service delivery. Now, we could "twist" de definition if we were to think of applications as full-fledged operating systems. That is, if we run a whole OS within this containers we would be actually achieving our goal: each container will behave as a network node so, in other words, we would only need to have a flimsy $36$ containers up at the same time; piece of cake.\\

            One of the questions we asked ourselves when trying to decide on a technology was: what makes a container different than a VM? If we go back to the section we devoted to virtual machines we'll notice how they run a full-fledged operating system as a guest. This implies each VM has its own \textit{kernel}.\\

            We don't need to dive that deep into what a kernel is as that would be going down the OS-side rabbit hole. We just need to know that the kernel is the piece of software "gluing" the hardware and user-land software (programs such as browsers) together. That is, it allows applications to access the computing resources in an organized manner enabling the sharing of resources amongst them. As we are telematics engineers we usually find the kernel concept easier to understand in terms of the abstractions it offers use; the network socket being the most familiar. Through it, our applications can leverage the networking capabilities of the machine they're running on.\\

            Unlike VMs, containers all share a single kernel. We can then think of containers as a way of isolating applications along with all their dependencies within a shared computing platform. We don't need "fancy" tools such as an hypervisor; we would only need to be very meticulous and know the kernel's offered facilities very well to achieve the end result offered by containers. Projects like \href{bocker}{https://github.com/p8952/bocker} prove one can achieve similar results to the ones provided by docker if only interested in a subset of the latter's capabilities. Nonetheless, we'll think of containers as light VMs throughout the development as, even though it's not exactly true, it won't hinder our development approach.\\

            \subsubsection{Containers and Docker}
                Once new terms start to be thrown around it's easy to get confused and that was exactly the case for us. One point we weren't that clear on was the difference between docker and containers. Are they the same thing?\\

                It turns out that the container technology is somewhat an standard. Now, the way that technology is implemented can vary. That's where docker comes into the picture as it offers an \textit{implementation} for containers which is loosely called the \texttt{docker engine}. This is a similar situation to that of VMs. The idea of a virtual machine has found two main implementations by VirtualBox and VMWare. Taking the network view of things it's like what happens with RFCs by the IETF. They propose a standard and several people try to implement it according to their coding style, level ok knowledge...\\

                If we are to be entirely correct when it comes to nomenclature we would have to say that our solution is going to be based on docker's container implementation.\\

            On top of container technology being lighter than that of VMs we also found the amount of documentation regarding the network infraestructure

             As our objective is virtualizing an entire network we'll be running a whole OS in each container. That's why we'll usually refer to these containers as net nodes rather than standalone applications. Even though containers have many subtleties to them we'll only use a reduced set of their capabilities so we don't need to dive any deeper into what containers really are. We can regard them as Virtual Machines and live a happy and long life. I beg docker experts not to hurt me in any way for remotely implying a container is similar to a VM though.